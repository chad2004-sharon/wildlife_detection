pip install torch
pip install torchvision
pip install torchsummary
pip install torchviz
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
from PIL import Image
from tempfile import TemporaryDirectory
from torchsummary import summary
from torchviz import make_dot

cudnn.benchmark = True
plt.ion()
from torchvision import transforms

from torchvision import datasets, transforms
import torch
import os

# Define the transformations
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# Correct path for data directory
data_dir = 'C:/Users/paulson/Downloads/archive(13)/train'

# Create dataset using the ImageFolder API (only for the 'train' folder)
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir), data_transforms[x])
                  for x in ['train']}  # No 'test' folder, so only 'train'

# Create dataloaders
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)
               for x in ['train']}

# Get the sizes of the datasets
dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}

# Get class names from the 'train' dataset
class_names = image_datasets['train'].classes

print(class_names)

# Set the device (GPU if available)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
def imshow(inp, title=None):
    """Display image for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)


inputs, classes = next(iter(dataloaders['train']))

out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])
def plot_training_results(train_losses, val_losses, train_acc, val_acc):
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train')
    plt.plot(val_losses, label='Validation')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='Train')
    plt.plot(val_acc, label='Validation')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.show()
import time
import torch
from tempfile import TemporaryDirectory

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    train_losses = []
    val_losses = []
    train_acc = []
    val_acc = []

    # Create a temporary directory to save training checkpoints
    with TemporaryDirectory() as tempdir:
        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')

        best_acc = 0.0

        for epoch in range(num_epochs):
            print(f'Epoch {epoch}/{num_epochs - 1}')
            print('-' * 10)

            # Loop through training and validation phases
            for phase in ['train', 'val']:  # Assuming you are using 'train' and 'val' phases
                if phase == 'train':
                    model.train()  # Set model to training mode
                else:
                    model.eval()   # Set model to evaluation mode

                running_loss = 0.0
                running_corrects = 0

                # Iterate over data
                for inputs, labels in dataloaders[phase]:
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    optimizer.zero_grad()

                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)

                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)

                if phase == 'train':
                    scheduler.step()

                epoch_loss = running_loss / dataset_sizes[phase]
                epoch_acc = running_corrects.double() / dataset_sizes[phase]

                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

                # Save losses and accuracies for later plotting
                if phase == 'train':
                    train_losses.append(epoch_loss)
                    train_acc.append(epoch_acc.cpu().numpy())  # Convert to numpy array on CPU
                else:
                    val_losses.append(epoch_loss)
                    val_acc.append(epoch_acc.cpu().numpy())  # Convert to numpy array on CPU

                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(model.state_dict(), best_model_params_path)

            print()

        time_elapsed = time.time() - since
        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
        print(f'Best validation Acc: {best_acc:.4f}')

        # Load best model weights
        model.load_state_dict(torch.load(best_model_params_path))

    # Plot the training results
    plot_training_results(train_losses, val_losses, train_acc, val_acc)
    return model
def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval() 
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['test']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {class_names[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

model_ft = models.resnet18(weights='IMAGENET1K_V1')
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.
# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.
model_ft.fc = nn.Linear(num_ftrs, len(class_names))

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
from torch.utils.data import random_split
from torchvision import datasets, transforms
import torch
import os

# Define the transformations for the training dataset
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# Correct path for data directory
data_dir = 'C:/Users/paulson/Downloads/archive(13)/train'

# Create the dataset for the 'train' folder
dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])

# Split the dataset into train and validation
train_size = int(0.8 * len(dataset))  # 80% train
val_size = len(dataset) - train_size  # 20% validation
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# Define dataloaders for both train and validation
dataloaders = {
    'train': torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4),
    'val': torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=4)
}

# Dataset sizes
dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}
from torchsummary import summary

# Visualize model architecture with input size, e.g., (3, 224, 224) for a 3-channel image of size 224x224
summary(model_ft, (3, 224, 224))
model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')
for param in model_conv.parameters():
    param.requires_grad = False

# Parameters of newly constructed modules have requires_grad=True by default
num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, len(class_names))

model_conv = model_conv.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that only parameters of final layer are being optimized as
# opposed to before.
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)
model_conv = train_model(model_conv, criterion, optimizer_conv,
                         exp_lr_scheduler, num_epochs=25)
from torchsummary import summary

# Make sure your model is on the correct device
model_ft.to(device)

# Show a summary of the model with input size (3, 224, 224)
summary(model_ft, input_size=(3, 224, 224), device=device.type)
from torchvision import datasets, transforms
import torch
import os

# Define the transformations
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# Correct path for data directory
data_dir = 'C:/Users/paulson/Downloads/archive(13)/train'

# Create dataset using the ImageFolder API (only for the 'train' folder)
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir), data_transforms[x])
                  for x in ['train']}  # No 'test' folder, so only 'train'

# Create dataloaders
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)
               for x in ['train']}

# Get the sizes of the datasets
dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}

# Get class names from the 'train' dataset
class_names = image_datasets['train'].classes

print(class_names)

# Set the device (GPU if available)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
pip install opencv-python
import cv2
import torch
from torchvision import transforms
from PIL import Image

# Define preprocessing steps (must match training pipeline)
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Predict class from single frame
def predict_from_frame(frame, model, class_names, device):
    try:
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(img_rgb)
        input_tensor = preprocess(img_pil).unsqueeze(0).to(device)

        model.eval()
        with torch.no_grad():
            outputs = model(input_tensor)
            _, preds = torch.max(outputs, 1)
            return class_names[preds.item()]
    except Exception as e:
        print(f"Prediction error: {e}")
        return "Unknown"

# Main function to run webcam and predict in real-time
def run_camera_animal_identifier(model, class_names, device):
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("❌ Error: Cannot access webcam.")
        return

    print("📷 Webcam running. Show an animal to the camera.")
    print("Press 'q' to quit.")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("❌ Failed to read frame.")
            break

        predicted_class = predict_from_frame(frame, model, class_names, device)

        # Display prediction
        cv2.putText(frame, f'Predicted: {predicted_class}', (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

        cv2.imshow('Animal Identifier (Press q to Quit)', frame)

        # Exit on 'q' key press
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
run_camera_animal_identifier(model_ft, class_names, device)


import torch
import torch.nn as nn
from torchvision import models, datasets
import os

# Set the device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Path to training data (used for class names)
data_dir = 'C:/Users/paulson/Downloads/archive(13)/train'  # Update path if needed

# Get class names
train_dataset = datasets.ImageFolder(root=data_dir)
class_names = train_dataset.classes  # ['cat', 'dog', 'lion', etc.]
num_classes = len(class_names)

# Define the model
model_ft = models.resnet18(pretrained=True)
for param in model_ft.parameters():
    param.requires_grad = False  # Freeze base model

# Replace final layer
model_ft.fc = nn.Linear(model_ft.fc.in_features, num_classes)

# Load your trained weights if available
model_path = 'model_weights.pth'  # Change this to your actual path
if os.path.exists(model_path):
    model_ft.load_state_dict(torch.load(model_path, map_location=device))
    print("✅ Loaded trained model weights.")
else:
    print("⚠️ Trained model weights not found. Model will run with random weights.")

# Send model to device
model_ft = model_ft.to(device)
